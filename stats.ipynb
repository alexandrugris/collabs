{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A stats refresher notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem no. 1\n",
    "\n",
    "You measure a value of 1.73 for a random variable with a mean of 1.20 and a standard deviation of 0.22. What is the z-value of the measurement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.409090909090909"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.73 - 1.20) / 0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem no. 2\n",
    "\n",
    "We have a sample of 100 voters and we know 56 would vote for candidate A and 44 would vote for candidate B. Assuming the sample is relevant, what is the probability that candidate B would win the elections? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04963869458396342\n",
      "-1.2087344460380716\n",
      "0.11338244176241852\n"
     ]
    }
   ],
   "source": [
    "p_A = 56 / 100\n",
    "p_B = (1-p_A)\n",
    "\n",
    "# standard error of the population proportion\n",
    "stderr = np.sqrt(p_A * p_B / 100.0) \n",
    "print(stderr)\n",
    "\n",
    "### A < 50%\n",
    "z = (0.5 - p_A) / stderr\n",
    "print(z) # how many standard deviations from the prop proportion is\n",
    "\n",
    "# what is the probability of < 0.5 givem 56/100 and our stderr\n",
    "print(st.norm.cdf(0.5, loc=p_A, scale=stderr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem no. 3\n",
    "\n",
    "What should be the number of voters that should declare they vote for candidate A for the candidate A to be certain that he will win the election? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.705543454095415\n",
      "0.052521495732662904\n"
     ]
    }
   ],
   "source": [
    "# p(A < 50%) = 5%. sample size is 100\n",
    "z=st.norm.ppf(0.05)\n",
    "#(0.5 - p_A) * sqrt(100) / sqrt((p_A - p_A*p_A)) = z\n",
    "# 0.5 * sqrt(100) - sqrt(100) * p_A = z * sqrt(p_A - p_A * p_A) | ^2\n",
    "# (0.5 * sqrt(100)) ^ 2 - 2 * 0.5 * sqrt(100) * sqrt(100) * p_A + 100 * p_A^2 = z^2 * (p_A - p_A^2)\n",
    "# 25 - 100 * p_A + 100 * p_A^2 - z^2 * p_A + z^2 * p_A^2 = 0\n",
    "# 25 - (100 + z^2) * p_A + (100 + z^2) * p_A^2 = 0\n",
    "print(z**2)\n",
    "# z = -1.64, z^2 = 2.7\n",
    "# 25 - 102.7 * p_A + 102.7 * p_A^2 = 0\n",
    "# x1,2 =(102.7 +- sqrt(102.7^2 - 4 * 102.7 * 25)) / (2 * 102.7)\n",
    "# x1 = 0.42\n",
    "# x2 = 0.58\n",
    "# so p_A should be 0.58 => to have a confidence level of 95% that p_A > 50 there should be at least 0.58 * 100 = 58 votes\n",
    "\n",
    "# test (ok to be slightly higher than 0.05 because I also rounded the z to 1.64):\n",
    "print(st.norm.cdf(0.5, loc=0.58, scale=np.sqrt((0.58 * (1-0.58) / 100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem no. 4\n",
    "\n",
    "In a similar analytical manner, we could also solve to find what would be the number of voters in the sample that would give us a confidence of 95% that candidate A would win, given that the sample proportion is 0.56. In this case the variable to search for would be N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049625670476904964\n"
     ]
    }
   ],
   "source": [
    "# the result of the cdf should be less than 0.05. The result is N=186\n",
    "print(st.norm.cdf(0.5, loc=0.56, scale=np.sqrt((0.56 * (1-0.56) / 186))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem no. 5\n",
    "\n",
    "A study claims that teenagers check their phones, on average, 56 times per day. A random experiment on 100 teenagers shows that the teenagers in the sample check their approximatively 55 times, on average, per day, with a standard deviation of the sample of 11. Can the initial study be invalidated?\n",
    "\n",
    "We will test two hypothesis:\n",
    "\n",
    "H0 - 57 times per day\n",
    "H11 - Not 57 times per day\n",
    "\n",
    "and \n",
    "\n",
    "H12 - Less than 57 times per day\n",
    "\n",
    "Speaking of hypothesis testing and when to choose one-sided test and when to choose a two-sided test, a very good [link](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n",
      "0.818348929556551\n",
      "Can H11 be accepted? False\n",
      "Can H12 be accepted? True\n"
     ]
    }
   ],
   "source": [
    "# first case, test H11 - double sided test\n",
    "# we estimate the population stddev the same as the sample stddev. \n",
    "# we can use this because the sample size is relatively large, larger than 30 (an empirical value)\n",
    "sem = 11 / np.sqrt(100)\n",
    "print(sem)\n",
    "\n",
    "p = st.norm.cdf(56, loc=55, scale=sem)\n",
    "print(p)\n",
    "\n",
    "print(\"Can H11 be accepted?\", p > 0.975 or p < 0.025)\n",
    "print(\"Can H12 be accepted?\", p < 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem no. 6\n",
    "\n",
    "Same problem as above, but instead of 100 teenagers only 10 are interviewed. The results are [43, 33, 55, 57, 55, 68, 45, 63, 64, 30]. Can we invalidate the hypothesis that teenagers check their phones, on average, 57 times per day?\n",
    "\n",
    "Since the sample size is small, we need to resort to the T-distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.3 12.38587905640936 3.9167588641630724\n",
      "Hypothesis can be rejected:  False 0.9102172502388542\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([43, 33, 55, 57, 55, 68, 45, 63, 64, 30])\n",
    "mean = np.mean(arr)\n",
    "std = np.std(arr)\n",
    "\n",
    " # we are interested in the variation of the mean, not of the variation in the sample\n",
    "sem = std/np.sqrt(len(arr))\n",
    "print (mean, std, sem)\n",
    "\n",
    "# df is degrees of freedom:\n",
    "p = st.t.cdf(57, df=len(arr)-1, loc=mean, scale=sem)\n",
    "print(\"Hypothesis can be rejected: \", p < 0.025 or p > 0.975, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem no. 7\n",
    "\n",
    "A vaccine is tested by splitting the population in two - a part of the population is given a placebo, the other part the new vaccine. The question to answer is if the new vaccine has an effect or not. Let's assume that the for placebo we have 2023 patients and 54 got the disease. The new vaccine was administered to 2050 people and only 23 got the sickness afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions: 0.026693030153237766 0.01121951219512195\n",
      "Variances: 1.2842566630981761e-05 5.4115291420612005e-06\n",
      "Difference: 0.015473517958115815 0.0042724812197414\n",
      "Confidence interval:  0.007099608642798908 0.02384742727343272\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "p1 = 54/2023\n",
    "p2 = 23/2050\n",
    "print(\"Proportions:\", p1, p2)\n",
    "\n",
    "variance_1 = p1 * (1-p1) / 2023\n",
    "variance_2 = p2 * (1-p2) / 2050\n",
    "print (\"Variances:\", variance_1, variance_2)\n",
    "\n",
    "# distribution of differences between the two populations\n",
    "mean_diff = p1-p2\n",
    "variance_diff = variance_1 + variance_2\n",
    "\n",
    "# SE of sample proportions\n",
    "SE = np.sqrt(variance_diff)\n",
    "print(\"Difference:\", mean_diff, SE)\n",
    "\n",
    "# 95% confidence interval for SE - conclusion, since the lower limit of the confidence interval > 0\n",
    "# most likely the vaccine helps a bit\n",
    "print(\"Confidence interval: \", mean_diff + SE * st.norm.ppf(0.025), mean_diff + SE * st.norm.ppf(0.975))\n",
    "\n",
    "# But are the sample distributions of the sample proportions normal to start with?\n",
    "print(p1 * 2023 > 10 and (1-p1) * 2023 > 10) # if n * p < 10 -> skewed to the right <=> median < mean\n",
    "print(p2 * 2050 > 10 and (1-p2) * 2050 > 10) # if n * (1-p) < 10 -> skewed to the left <=> median > mean\n",
    "# In our case, both are roughly normally distributed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem no. 8\n",
    "\n",
    "Let's assume the usual seasonal birthrates for a hospital are as follows - winter 15%, spring - 25%, summmer - 30%, autumn - 30% out of an expected of 80 babies. In the first year of the pandemic the following rates have been registered - winter 10 babies, spring - 22 babies, summer - 28 babies, autumn - 40 babies. Was the 1st pandemic year an unsual year for this particular hospital? \n",
    "\n",
    "- *H0* - the first year of the pandemic was a normal year\n",
    "- *H1* - the first year of the pandemic was an outstanding year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 20.0 24.0 24.0\n",
      "0.3333333333333333 0.2 0.6666666666666666 10.666666666666666\n",
      "11.866666666666665\n",
      "P-value: 0.9921458560317754 , can we reject: True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexandrugris/Downloads/GitHub/collabs/stats.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexandrugris/Downloads/GitHub/collabs/stats.ipynb#ch0000017?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mP-value:\u001b[39m\u001b[39m\"\u001b[39m, p, \u001b[39m\"\u001b[39m\u001b[39m, can we reject:\u001b[39m\u001b[39m\"\u001b[39m, p \u001b[39m<\u001b[39m \u001b[39m0.025\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m0.975\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexandrugris/Downloads/GitHub/collabs/stats.ipynb#ch0000017?line=25'>26</a>\u001b[0m \u001b[39m# and directly with python function - same returns\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexandrugris/Downloads/GitHub/collabs/stats.ipynb#ch0000017?line=26'>27</a>\u001b[0m st\u001b[39m.\u001b[39;49mchisquare([\u001b[39m10\u001b[39;49m, \u001b[39m22\u001b[39;49m, \u001b[39m28\u001b[39;49m, \u001b[39m40\u001b[39;49m], f_exp\u001b[39m=\u001b[39;49m[avg_babies_w, avg_babies_sp, avg_babies_su, avg_babies_au])\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py:6911\u001b[0m, in \u001b[0;36mchisquare\u001b[0;34m(f_obs, f_exp, ddof, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6786'>6787</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchisquare\u001b[39m(f_obs, f_exp\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ddof\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6787'>6788</a>\u001b[0m     \u001b[39m\"\"\"Calculate a one-way chi-square test.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6788'>6789</a>\u001b[0m \n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6789'>6790</a>\u001b[0m \u001b[39m    The chi-square test tests the null hypothesis that the categorical data\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6908'>6909</a>\u001b[0m \n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6909'>6910</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6910'>6911</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m power_divergence(f_obs, f_exp\u001b[39m=\u001b[39;49mf_exp, ddof\u001b[39m=\u001b[39;49mddof, axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6911'>6912</a>\u001b[0m                             lambda_\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpearson\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py:6753\u001b[0m, in \u001b[0;36mpower_divergence\u001b[0;34m(f_obs, f_exp, ddof, axis, lambda_)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6746'>6747</a>\u001b[0m     \u001b[39mif\u001b[39;00m diff_gt_tol:\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6747'>6748</a>\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFor each axis slice, the sum of the observed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6748'>6749</a>\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfrequencies must agree with the sum of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6749'>6750</a>\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected frequencies to a relative tolerance \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6750'>6751</a>\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof \u001b[39m\u001b[39m{\u001b[39;00mrtol\u001b[39m}\u001b[39;00m\u001b[39m, but the percent differences are:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6751'>6752</a>\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrelative_diff\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6752'>6753</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6754'>6755</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6755'>6756</a>\u001b[0m     \u001b[39m# Ignore 'invalid' errors so the edge case of a data set with length 0\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6756'>6757</a>\u001b[0m     \u001b[39m# is handled without spurious warnings.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/alexandrugris/miniforge3/lib/python3.9/site-packages/scipy/stats/_stats_py.py?line=6757'>6758</a>\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.25"
     ]
    }
   ],
   "source": [
    "avg_babies_w = 0.15 * 80\n",
    "avg_babies_sp = 0.25 * 80\n",
    "avg_babies_su = 0.30 * 80\n",
    "avg_babies_au = 0.30 * 80\n",
    "\n",
    "print(avg_babies_w, avg_babies_sp, avg_babies_su, avg_babies_au)\n",
    "\n",
    "chi_sq_w = (avg_babies_w - 10) ** 2 / avg_babies_w\n",
    "chi_sq_sp = (avg_babies_sp - 22) ** 2 / avg_babies_sp\n",
    "chi_sq_su = (avg_babies_su - 28) ** 2 / avg_babies_su\n",
    "chi_sq_au = (avg_babies_au - 40) ** 2 /avg_babies_au\n",
    "\n",
    "# the smaller the individual chi_sq is, the category fits to the average\n",
    "# in our case, autumn does not fit at all, with the rest more or less inline\n",
    "print(chi_sq_w, chi_sq_sp, chi_sq_su, chi_sq_au)\n",
    "\n",
    "chi_sq = chi_sq_w + chi_sq_sp + chi_sq_su + chi_sq_au\n",
    "print(chi_sq)\n",
    "\n",
    "degrees_of_freedom = 4 - 1 # 4 seasons - 1\n",
    "\n",
    "p = st.chi2.cdf(chi_sq, df=degrees_of_freedom)\n",
    "# we can reject the null hypothesis that this was a normal year.\n",
    "print(\"P-value:\", p, \", can we reject:\", p < 0.025 or p > 0.975) \n",
    "\n",
    "# and directly with python function - same returns\n",
    "st.chisquare([10, 22, 28, 40], f_exp=[avg_babies_w, avg_babies_sp, avg_babies_su, avg_babies_au])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem no. 9\n",
    "\n",
    "A company has 4 teams, each led by a different manager, each with 4 people. Let's assume the managers are A, B, C and D. The manager ratings for each individual team as as follows:\n",
    "\n",
    "- *A* - 5, 5, 3, 3,\n",
    "- *B* - 8, 5, 4, 3,\n",
    "- *C* - 8, 6, 5, 5,\n",
    "- *D* - 8, 6, 4, 2,\n",
    "\n",
    "We want to test:\n",
    "\n",
    "- *H0* - all managers are roughly the same (same mean)\n",
    "- *H1* - not all managers are the same (groups have different mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-statistic: 0.7272727272727273 p-value: 0.5551086637384909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.7272727272727273, pvalue=0.5551086637384908)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-way ANOVA\n",
    "scores = np.array([\n",
    "    [5, 5, 3, 3],\n",
    "    [8, 5, 4, 3],\n",
    "    [8, 6, 5, 5],\n",
    "    [8, 6, 4, 2]])\n",
    "\n",
    "means = np.mean(scores, axis=1)\n",
    "grand_mean = np.mean(means)\n",
    "#print(means, grand_mean)\n",
    "\n",
    "# total sum of squares (for each, with the grand_mean)\n",
    "SST = np.sum(np.sum((scores - grand_mean) ** 2, axis=1))\n",
    "#print(SST)\n",
    "\n",
    "# sum of squares within (for each, with the group mean)\n",
    "SSW = np.sum(np.sum([(scores[i] - means[i]) ** 2 for i in range(0, 4)], axis=1))\n",
    "#print(SSW)\n",
    "\n",
    "# sum of squares between\n",
    "SSB = SST - SSW\n",
    "\n",
    "# f_statistic - comparing the variance between groups with the variance within groups\n",
    "m = 4 # number of managers (groups) \n",
    "nt = scores.size # the total number of observations \n",
    "\n",
    "dfn = m-1 # degrees of freedom within number of groups\n",
    "dfd = nt-m # degrees of freedom within the total dataset\n",
    "\n",
    "f_statistic = (SSB / dfn) / (SSW / dfd)\n",
    "print(\"f-statistic:\", f_statistic, \"p-value:\", 1 - st.f.cdf(f_statistic, dfn=dfn, dfd=dfd))\n",
    "\n",
    "# and directly with the scipy\n",
    "st.f_oneway(scores[0], scores[1], scores[2], scores[3])\n",
    "\n",
    "# in our case, there is no significant level of difference bwtween these 4 managers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refresher certificate [Statistics Fundamentals 2](https://drive.google.com/file/d/1pKkYFOfSFDEKpMMd0oQEXduEt3hpDlow/view?usp=sharing) and [Statistics Fundamentals 3](https://drive.google.com/file/d/1EVqawMrUNbKIDwuonr2ZHwxwuyJGYPIE/view?usp=sharing)\n",
    "\n",
    "As well as deeper dive on my own [blog](https://alexandrugris.github.io/statistics/2019/12/24/stats-again.html)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
