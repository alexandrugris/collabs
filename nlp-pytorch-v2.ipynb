{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3188.06s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Requirement already satisfied: pip in /opt/homebrew/lib/python3.11/site-packages (23.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "3194.68s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Requirement already satisfied: tensorflow in /opt/homebrew/lib/python3.11/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /opt/homebrew/lib/python3.11/site-packages (4.9.2)\n",
      "Requirement already satisfied: torch in /opt/homebrew/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/lib/python3.11/site-packages (0.15.1)\n",
      "Requirement already satisfied: torchtext in /opt/homebrew/lib/python3.11/site-packages (0.15.1)\n",
      "Requirement already satisfied: ipywidgets in /opt/homebrew/lib/python3.11/site-packages (8.1.0)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-macos==2.13.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (67.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.56.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: array-record in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-datasets) (0.4.0)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-datasets) (8.1.3)\n",
      "Requirement already satisfied: dm-tree in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-datasets) (1.4.1)\n",
      "Requirement already satisfied: promise in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-datasets) (5.9.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-datasets) (2.29.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-datasets) (1.13.1)\n",
      "Requirement already satisfied: toml in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-datasets) (4.65.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.11/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: torchdata==0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from torchtext) (0.6.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/homebrew/lib/python3.11/site-packages (from torchdata==0.6.0->torchtext) (1.26.15)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/homebrew/lib/python3.11/site-packages (from ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/homebrew/lib/python3.11/site-packages (from ipywidgets) (8.13.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/homebrew/lib/python3.11/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/homebrew/lib/python3.11/site-packages (from ipywidgets) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/homebrew/lib/python3.11/site-packages (from ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: importlib_resources in /opt/homebrew/lib/python3.11/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (6.0.0)\n",
      "Requirement already satisfied: zipp in /opt/homebrew/lib/python3.11/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (3.16.2)\n",
      "Requirement already satisfied: backcall in /opt/homebrew/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/homebrew/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/homebrew/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/homebrew/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/homebrew/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/homebrew/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/homebrew/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/homebrew/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /opt/homebrew/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->tensorflow-datasets) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.60.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/homebrew/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/homebrew/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/homebrew/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/homebrew/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/homebrew/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/homebrew/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install tensorflow tensorflow-datasets torch torchvision torchtext ipywidgets unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import unidecode\n",
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'and when you improve searchability , you act...</td>\n",
       "      <td>b'e quando melhoramos a procura , tiramos a \\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'but what if it were active ?'</td>\n",
       "      <td>b'mas e se estes fatores fossem ativos ?'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b\"but they did n't test for curiosity .\"</td>\n",
       "      <td>b'mas eles n\\xc3\\xa3o tinham a curiosidade de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'and this conscious defiance is why i , as an...</td>\n",
       "      <td>b'e esta rebeldia consciente \\xc3\\xa9 a raz\\xc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'you can use everything on the table on me .'</td>\n",
       "      <td>b\"`` `` '' podem usar tudo sobre a mesa no meu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en   \n",
       "0  b'and when you improve searchability , you act...  \\\n",
       "1                    b'but what if it were active ?'   \n",
       "2           b\"but they did n't test for curiosity .\"   \n",
       "3  b'and this conscious defiance is why i , as an...   \n",
       "4     b'you can use everything on the table on me .'   \n",
       "\n",
       "                                                  pt  \n",
       "0  b'e quando melhoramos a procura , tiramos a \\x...  \n",
       "1          b'mas e se estes fatores fossem ativos ?'  \n",
       "2  b'mas eles n\\xc3\\xa3o tinham a curiosidade de ...  \n",
       "3  b'e esta rebeldia consciente \\xc3\\xa9 a raz\\xc...  \n",
       "4  b\"`` `` '' podem usar tudo sobre a mesa no meu...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another good dataset here:\n",
    "# http://www.manythings.org/anki/\n",
    "\n",
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
    "                               with_info=True,\n",
    "                               as_supervised=True)\n",
    "\n",
    "train_examples = tfds.as_dataframe(ds = examples['train'], ds_info=metadata)\n",
    "train_examples.head()\n",
    "\n",
    "#val_examples = tfds.as_dataframe(ds = examples['validation'], ds_info=metadata)\n",
    "#test_examples = tfds.as_dataframe(ds = examples['validation'], ds_info=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(examples):\n",
    "    en_texts = examples['en'].to_numpy()\n",
    "    pt_texts = examples['pt'].to_numpy()\n",
    "    return en_texts, pt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<START> e quando melhoramos a procura tiramos a unica vantagem da impressao que e a serendipidade <END>', '<START> mas e se estes fatores fossem ativos ? <END>']\n"
     ]
    }
   ],
   "source": [
    "en_texts, pt_texts = process_dataframe(train_examples)\n",
    "\n",
    "def to_ASCII_lower_case(s): # s is numpy byte string\n",
    "    \n",
    "    # utf-8 string to lowercase\n",
    "    s = s.decode('utf-8').lower()\n",
    "\n",
    "    # replace all diacritics with transliteration\n",
    "    s = unidecode.unidecode(s)\n",
    "\n",
    "    # regexs\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "\n",
    "    return f'<START> {s.strip()} <END>'\n",
    "\n",
    "\n",
    "en_texts = [to_ASCII_lower_case(s) for s in en_texts]\n",
    "pt_texts = [to_ASCII_lower_case(s) for s in pt_texts]\n",
    "\n",
    "print(pt_texts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatmap_strings(list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab = torchtext.vocab.vocab(en_counter, specials=['<unk>', '<pad>', '<eos>'], special_first=True)\n",
    "fr_vocab = torchtext.vocab.vocab(fr_counter, specials=['<unk>', '<pad>', '<eos>', '<sos>'], special_first=True)\n",
    "\n",
    "PAD_EN = en_vocab['<pad>']\n",
    "PAD_FR = fr_vocab['<pad>']\n",
    "EOS_EN = en_vocab['<eos>']\n",
    "EOS_FR = fr_vocab['<eos>']\n",
    "SOS_FR = fr_vocab['<sos>']\n",
    "\n",
    "en_vocab.set_default_index = en_vocab['<unk>']\n",
    "fr_vocab.set_default_index = fr_vocab['<unk>']\n",
    "\n",
    "del en_counter\n",
    "del fr_counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(batch):\n",
    "    eb = []\n",
    "    fb = [] \n",
    "    for e, f in batch:\n",
    "        tte = torch.LongTensor([en_vocab[k] for k in e])\n",
    "        ttf = torch.LongTensor([fr_vocab[k] for k in f])\n",
    "\n",
    "        eb.append(torch.cat([tte, torch.LongTensor([EOS_EN])], dim=0))\n",
    "        fb.append(torch.cat([ttf, torch.LongTensor([EOS_FR])], dim=0))\n",
    "\n",
    "        en_batch = pad_sequence(eb, batch_first=True, padding_value=PAD_EN)\n",
    "        fr_batch = pad_sequence(fb, batch_first=True, padding_value=PAD_FR)\n",
    "\n",
    "    return en_batch, fr_batch \n",
    "\n",
    "dl = DataLoader(df, batch_size=128, shuffle=True, collate_fn=make_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 25]) torch.Size([128, 24])\n",
      "tensor([ 60, 240, 291,  22, 129,   4,   2,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1])\n"
     ]
    }
   ],
   "source": [
    "_, batch = next(enumerate(dl))\n",
    "print(batch[0].shape, batch[1].shape)\n",
    "print(batch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 25, 64])\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module): # TODO: make this bidirectional\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "\n",
    "        # just 1 lstm layer\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        return self.relu(self.linear(output))\n",
    "\n",
    "# test\n",
    "enc = Encoder(len(en_vocab), 64)\n",
    "o_encoder = enc.forward(batch[0])\n",
    "\n",
    "print(o_encoder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 25, 64])\n",
      "torch.Size([128, 1, 64])\n",
      "torch.Size([128, 2, 64])\n",
      "torch.Size([128, 3, 64])\n"
     ]
    }
   ],
   "source": [
    "class PreAttentionDecoder(nn.Module):\n",
    "    ### TODO: implement teacher forcing, add to each sequence a <SOS> character\n",
    "    \n",
    "    def __init__(self, target_vocab, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(target_vocab, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=False)\n",
    "\n",
    "    def forward(self, input, word_by_word_idx=-1):\n",
    "\n",
    "        # shift right with the SOS token\n",
    "        shift_right = torch.LongTensor([SOS_FR] * input.shape[0]).reshape((input.shape[0], 1)).to(device)\n",
    "        input = torch.cat([shift_right, input], dim=1)\n",
    "\n",
    "        # full sentence\n",
    "        if word_by_word_idx == -1: \n",
    "            embedded = self.embedding(input)\n",
    "            output, _ = self.lstm(embedded)\n",
    "            return output\n",
    "\n",
    "        else:\n",
    "            # a single word\n",
    "            embedded = self.embedding(input[:, word_by_word_idx : word_by_word_idx + 1])\n",
    "            if word_by_word_idx == 0:\n",
    "                self.output, self.prev_state = self.lstm(embedded)\n",
    "            else:\n",
    "                output, self.prev_state = self.lstm(embedded, self.prev_state)    \n",
    "                self.output = torch.cat([self.output, output], axis=1)\n",
    "            \n",
    "            return self.output\n",
    "\n",
    "pad = PreAttentionDecoder(len(fr_vocab), 64).to(device)\n",
    "o_preattn = pad.forward(batch[1].to(device))\n",
    "\n",
    "print(o_preattn.shape)\n",
    "\n",
    "o_preattn_word = None\n",
    "for i in range(0, 3):\n",
    "    o_preattn_word = pad.forward(batch[1].to(device), i)\n",
    "    print(o_preattn_word.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, encoder_output, pre_attention_decoder_output):\n",
    "        key = encoder_output # what is input\n",
    "        query = pre_attention_decoder_output # what has been so far translated\n",
    "        value = encoder_output # the value we want to translate\n",
    "\n",
    "        dk = torch.sqrt(torch.Tensor([key.shape[-1]])).to(device)\n",
    "        key_transpose = torch.transpose(key, 1, 2)\n",
    "        \n",
    "        mm = torch.bmm(query, key_transpose) / dk\n",
    "        mm = nn.functional.softmax(mm, dim=-1)\n",
    "        ret = torch.bmm(mm, value)    \n",
    "        return  ret\n",
    "    \n",
    "\n",
    "dpa = ScaledDotProductAttention().to(device)\n",
    "\n",
    "# all at once\n",
    "o_attn = dpa.forward(o_encoder.to(device), o_preattn.to(device))\n",
    "#print(o_attn[0].shape)\n",
    "\n",
    "# word by word\n",
    "o_attn_word = dpa.forward(o_encoder.to(device), o_preattn_word.to(device))\n",
    "#print(o_attn_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2645, 0.2645, 0.4711],\n",
       "         [0.4711, 0.2645, 0.2645],\n",
       "         [0.2645, 0.4711, 0.2645]]], device='mps:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# let's check the ScaledDotProductAttention\n",
    "t1 = torch.Tensor([[[0, 0, 1], [1, 0, 0], [0, 1, 0]]]).to(device)\n",
    "t2 = torch.Tensor([[[0, 0, 1], [1, 0, 0], [0, 1, 0]]]).to(device)\n",
    "\n",
    "dpa.forward(t1, t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27139])\n",
      "tensor(15952, device='mps:0') tensor(-8.1260, device='mps:0', grad_fn=<MaxBackward1>) tensor([ -9.7784, -10.9686,  -9.8908,  -9.9190, -10.0271, -10.4247, -10.5776,\n",
      "        -10.2212, -10.7144, -10.5686], device='mps:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        NUM_LAYERS = 2\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, num_layers=NUM_LAYERS)\n",
    "    \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size * 2),\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size * 2, len(fr_vocab)), \n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward (self, input, word_idx=-1):\n",
    "\n",
    "        if word_idx == -1 or word_idx == 0:\n",
    "            o, self.h = self.gru(input)\n",
    "        else:\n",
    "            o, self.h = self.gru(input[:, word_idx : word_idx + 1, :], self.h)\n",
    "\n",
    "        # take only the last value\n",
    "        o = o[:, -1, :] \n",
    "        return self.seq(o)\n",
    "    \n",
    "dec = Decoder(64).to(device)\n",
    "o = dec.forward(o_attn)\n",
    "print(o.shape)\n",
    "print(torch.argmax(o[0]), torch.max(o[0]), o[0][0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training now, will get input and predict the last word. boom\n",
    "class Translator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(len(en_vocab), 64)\n",
    "        self.pre_attn_decoder = PreAttentionDecoder(len(fr_vocab), 64)\n",
    "        self.attention = ScaledDotProductAttention()\n",
    "        self.decoder = Decoder(64)\n",
    "        self.past_enc = None\n",
    "\n",
    "    def forward(self, sentence, translated_sequence_so_far, word_by_word_idx = -1):\n",
    "\n",
    "        # either batch prediction or char by char, first time\n",
    "        if word_by_word_idx == -1 or word_by_word_idx == 0:\n",
    "            enc = self.encoder.forward(sentence)\n",
    "            self.past_enc = enc\n",
    "        else:\n",
    "            enc=self.past_enc\n",
    "            \n",
    "        pre_attn = self.pre_attn_decoder.forward(translated_sequence_so_far, word_by_word_idx)\n",
    "        attn = self.attention.forward(enc, pre_attn)\n",
    "        return self.decoder.forward(attn, word_by_word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translator(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(15962, 64)\n",
      "    (lstm): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
      "    (linear): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (pre_attn_decoder): PreAttentionDecoder(\n",
      "    (embedding): Embedding(27139, 64)\n",
      "    (lstm): LSTM(64, 64, batch_first=True)\n",
      "  )\n",
      "  (attention): ScaledDotProductAttention()\n",
      "  (decoder): Decoder(\n",
      "    (gru): GRU(64, 64, num_layers=2, batch_first=True)\n",
      "    (seq): Sequential(\n",
      "      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=27139, bias=True)\n",
      "      (5): LogSoftmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total params:  6426115\n",
      "loss: 3.065207, seq_len:   29 [    0/ 1703]\n",
      "loss: 3.582874, seq_len:   23 [   10/ 1703]\n",
      "loss: 3.374472, seq_len:   25 [   20/ 1703]\n",
      "loss: 3.771408, seq_len:   20 [   30/ 1703]\n",
      "loss: 3.354229, seq_len:   26 [   40/ 1703]\n",
      "loss: 3.684069, seq_len:   21 [   50/ 1703]\n",
      "loss: 3.487563, seq_len:   22 [   60/ 1703]\n",
      "loss: 3.490820, seq_len:   21 [   70/ 1703]\n",
      "loss: 3.623409, seq_len:   22 [   80/ 1703]\n",
      "loss: 3.472228, seq_len:   22 [   90/ 1703]\n",
      "loss: 3.277095, seq_len:   25 [  100/ 1703]\n",
      "loss: 3.267950, seq_len:   26 [  110/ 1703]\n",
      "loss: 3.876959, seq_len:   20 [  120/ 1703]\n",
      "loss: 2.964032, seq_len:   32 [  130/ 1703]\n",
      "loss: 3.032231, seq_len:   31 [  140/ 1703]\n",
      "loss: 3.912083, seq_len:   17 [  150/ 1703]\n",
      "loss: 3.920122, seq_len:   19 [  160/ 1703]\n",
      "loss: 3.832548, seq_len:   20 [  170/ 1703]\n",
      "loss: 2.879596, seq_len:   35 [  180/ 1703]\n",
      "loss: 3.430890, seq_len:   23 [  190/ 1703]\n",
      "loss: 3.665318, seq_len:   21 [  200/ 1703]\n",
      "loss: 3.546147, seq_len:   22 [  210/ 1703]\n",
      "loss: 3.784065, seq_len:   18 [  220/ 1703]\n",
      "loss: 3.383702, seq_len:   23 [  230/ 1703]\n",
      "loss: 3.060718, seq_len:   30 [  240/ 1703]\n",
      "loss: 3.151861, seq_len:   28 [  250/ 1703]\n",
      "loss: 3.554981, seq_len:   22 [  260/ 1703]\n",
      "loss: 2.573691, seq_len:   41 [  270/ 1703]\n",
      "loss: 3.175726, seq_len:   27 [  280/ 1703]\n",
      "loss: 2.894845, seq_len:   33 [  290/ 1703]\n",
      "loss: 3.432589, seq_len:   23 [  300/ 1703]\n",
      "loss: 3.663928, seq_len:   21 [  310/ 1703]\n",
      "loss: 2.901285, seq_len:   33 [  320/ 1703]\n",
      "loss: 3.867089, seq_len:   19 [  330/ 1703]\n",
      "loss: 3.203046, seq_len:   27 [  340/ 1703]\n",
      "loss: 3.296947, seq_len:   23 [  350/ 1703]\n",
      "loss: 3.224049, seq_len:   25 [  360/ 1703]\n",
      "loss: 3.248638, seq_len:   25 [  370/ 1703]\n",
      "loss: 3.609892, seq_len:   20 [  380/ 1703]\n",
      "loss: 3.800124, seq_len:   19 [  390/ 1703]\n",
      "loss: 3.333456, seq_len:   24 [  400/ 1703]\n",
      "loss: 3.438815, seq_len:   21 [  410/ 1703]\n",
      "loss: 3.394836, seq_len:   22 [  420/ 1703]\n",
      "loss: 3.317300, seq_len:   22 [  430/ 1703]\n",
      "loss: 3.024184, seq_len:   29 [  440/ 1703]\n",
      "loss: 3.488356, seq_len:   21 [  450/ 1703]\n",
      "loss: 3.175468, seq_len:   26 [  460/ 1703]\n",
      "loss: 3.737129, seq_len:   19 [  470/ 1703]\n",
      "loss: 3.201804, seq_len:   24 [  480/ 1703]\n",
      "loss: 3.535307, seq_len:   20 [  490/ 1703]\n",
      "loss: 3.677717, seq_len:   20 [  500/ 1703]\n",
      "loss: 3.186749, seq_len:   24 [  510/ 1703]\n",
      "loss: 3.677710, seq_len:   19 [  520/ 1703]\n",
      "loss: 3.783973, seq_len:   18 [  530/ 1703]\n",
      "loss: 3.556268, seq_len:   20 [  540/ 1703]\n",
      "loss: 3.721537, seq_len:   20 [  550/ 1703]\n",
      "loss: 3.971430, seq_len:   17 [  560/ 1703]\n",
      "loss: 3.513729, seq_len:   20 [  570/ 1703]\n",
      "loss: 2.746200, seq_len:   33 [  580/ 1703]\n",
      "loss: 3.106137, seq_len:   26 [  590/ 1703]\n",
      "loss: 3.451752, seq_len:   21 [  600/ 1703]\n",
      "loss: 3.452664, seq_len:   21 [  610/ 1703]\n",
      "loss: 3.068421, seq_len:   25 [  620/ 1703]\n",
      "loss: 3.543254, seq_len:   21 [  630/ 1703]\n",
      "loss: 3.744128, seq_len:   19 [  640/ 1703]\n",
      "loss: 2.977227, seq_len:   28 [  650/ 1703]\n",
      "loss: 3.297010, seq_len:   24 [  660/ 1703]\n",
      "loss: 3.546649, seq_len:   21 [  670/ 1703]\n",
      "loss: 3.377220, seq_len:   21 [  680/ 1703]\n",
      "loss: 3.415057, seq_len:   22 [  690/ 1703]\n",
      "loss: 3.286550, seq_len:   22 [  700/ 1703]\n",
      "loss: 3.134854, seq_len:   23 [  710/ 1703]\n",
      "loss: 3.295560, seq_len:   23 [  720/ 1703]\n",
      "loss: 2.970254, seq_len:   26 [  730/ 1703]\n",
      "loss: 3.772750, seq_len:   18 [  740/ 1703]\n",
      "loss: 3.658914, seq_len:   19 [  750/ 1703]\n",
      "loss: 3.170231, seq_len:   23 [  760/ 1703]\n",
      "loss: 3.692417, seq_len:   18 [  770/ 1703]\n",
      "loss: 3.350095, seq_len:   22 [  780/ 1703]\n",
      "loss: 3.216517, seq_len:   23 [  790/ 1703]\n",
      "loss: 4.053707, seq_len:   16 [  800/ 1703]\n",
      "loss: 3.354171, seq_len:   21 [  810/ 1703]\n",
      "loss: 2.672806, seq_len:   31 [  820/ 1703]\n",
      "loss: 3.808712, seq_len:   18 [  830/ 1703]\n",
      "loss: 3.524004, seq_len:   20 [  840/ 1703]\n",
      "loss: 2.873487, seq_len:   28 [  850/ 1703]\n",
      "loss: 3.697344, seq_len:   19 [  860/ 1703]\n",
      "loss: 3.452874, seq_len:   19 [  870/ 1703]\n",
      "loss: 3.387750, seq_len:   21 [  880/ 1703]\n",
      "loss: 2.743250, seq_len:   29 [  890/ 1703]\n",
      "loss: 3.708825, seq_len:   18 [  900/ 1703]\n",
      "loss: 2.874897, seq_len:   27 [  910/ 1703]\n",
      "loss: 3.564113, seq_len:   19 [  920/ 1703]\n",
      "loss: 2.483022, seq_len:   36 [  930/ 1703]\n",
      "loss: 3.789522, seq_len:   18 [  940/ 1703]\n",
      "loss: 3.105242, seq_len:   24 [  950/ 1703]\n",
      "loss: 3.713083, seq_len:   19 [  960/ 1703]\n",
      "loss: 2.887329, seq_len:   26 [  970/ 1703]\n",
      "loss: 2.836445, seq_len:   27 [  980/ 1703]\n",
      "loss: 2.663048, seq_len:   29 [  990/ 1703]\n",
      "loss: 3.622400, seq_len:   19 [ 1000/ 1703]\n",
      "loss: 3.442878, seq_len:   20 [ 1010/ 1703]\n",
      "loss: 3.098393, seq_len:   24 [ 1020/ 1703]\n",
      "loss: 3.260925, seq_len:   22 [ 1030/ 1703]\n",
      "loss: 3.753180, seq_len:   18 [ 1040/ 1703]\n",
      "loss: 3.233353, seq_len:   22 [ 1050/ 1703]\n",
      "loss: 3.674876, seq_len:   18 [ 1060/ 1703]\n",
      "loss: 2.864715, seq_len:   26 [ 1070/ 1703]\n",
      "loss: 2.806065, seq_len:   28 [ 1080/ 1703]\n",
      "loss: 2.619271, seq_len:   32 [ 1090/ 1703]\n",
      "loss: 3.262305, seq_len:   21 [ 1100/ 1703]\n",
      "loss: 2.857841, seq_len:   27 [ 1110/ 1703]\n",
      "loss: 2.696918, seq_len:   28 [ 1120/ 1703]\n",
      "loss: 3.408945, seq_len:   20 [ 1130/ 1703]\n",
      "loss: 3.170698, seq_len:   23 [ 1140/ 1703]\n",
      "loss: 3.854195, seq_len:   18 [ 1150/ 1703]\n",
      "loss: 2.492918, seq_len:   33 [ 1160/ 1703]\n",
      "loss: 3.561760, seq_len:   19 [ 1170/ 1703]\n",
      "loss: 3.803262, seq_len:   17 [ 1180/ 1703]\n",
      "loss: 3.344515, seq_len:   20 [ 1190/ 1703]\n",
      "loss: 2.607480, seq_len:   32 [ 1200/ 1703]\n",
      "loss: 3.016187, seq_len:   25 [ 1210/ 1703]\n",
      "loss: 2.984654, seq_len:   26 [ 1220/ 1703]\n",
      "loss: 3.261153, seq_len:   21 [ 1230/ 1703]\n",
      "loss: 3.733820, seq_len:   18 [ 1240/ 1703]\n",
      "loss: 3.581664, seq_len:   20 [ 1250/ 1703]\n",
      "loss: 2.588310, seq_len:   32 [ 1260/ 1703]\n",
      "loss: 3.051092, seq_len:   25 [ 1270/ 1703]\n",
      "loss: 3.154288, seq_len:   21 [ 1280/ 1703]\n",
      "loss: 3.875939, seq_len:   18 [ 1290/ 1703]\n",
      "loss: 2.842638, seq_len:   26 [ 1300/ 1703]\n",
      "loss: 2.835382, seq_len:   27 [ 1310/ 1703]\n",
      "loss: 3.804214, seq_len:   17 [ 1320/ 1703]\n",
      "loss: 2.680016, seq_len:   28 [ 1330/ 1703]\n",
      "loss: 3.493521, seq_len:   19 [ 1340/ 1703]\n",
      "loss: 2.819556, seq_len:   27 [ 1350/ 1703]\n",
      "loss: 3.477231, seq_len:   19 [ 1360/ 1703]\n",
      "loss: 3.404449, seq_len:   20 [ 1370/ 1703]\n",
      "loss: 2.881932, seq_len:   26 [ 1380/ 1703]\n",
      "loss: 3.148398, seq_len:   22 [ 1390/ 1703]\n",
      "loss: 3.208375, seq_len:   22 [ 1400/ 1703]\n",
      "loss: 3.750809, seq_len:   18 [ 1410/ 1703]\n",
      "loss: 2.941800, seq_len:   25 [ 1420/ 1703]\n",
      "loss: 3.080327, seq_len:   23 [ 1430/ 1703]\n",
      "loss: 3.213963, seq_len:   22 [ 1440/ 1703]\n",
      "loss: 2.988838, seq_len:   24 [ 1450/ 1703]\n",
      "loss: 3.123151, seq_len:   24 [ 1460/ 1703]\n",
      "loss: 2.899133, seq_len:   27 [ 1470/ 1703]\n",
      "loss: 3.299893, seq_len:   21 [ 1480/ 1703]\n",
      "loss: 2.992321, seq_len:   25 [ 1490/ 1703]\n",
      "loss: 3.189344, seq_len:   23 [ 1500/ 1703]\n",
      "loss: 2.674015, seq_len:   27 [ 1510/ 1703]\n",
      "loss: 3.886365, seq_len:   16 [ 1520/ 1703]\n",
      "loss: 3.115075, seq_len:   22 [ 1530/ 1703]\n",
      "loss: 3.037059, seq_len:   25 [ 1540/ 1703]\n",
      "loss: 3.602356, seq_len:   18 [ 1550/ 1703]\n",
      "loss: 2.666465, seq_len:   29 [ 1560/ 1703]\n",
      "loss: 3.360918, seq_len:   20 [ 1570/ 1703]\n",
      "loss: 3.327602, seq_len:   19 [ 1580/ 1703]\n",
      "loss: 3.038781, seq_len:   22 [ 1590/ 1703]\n",
      "loss: 2.641391, seq_len:   28 [ 1600/ 1703]\n",
      "loss: 3.010497, seq_len:   23 [ 1610/ 1703]\n",
      "loss: 2.860249, seq_len:   26 [ 1620/ 1703]\n",
      "loss: 2.708167, seq_len:   28 [ 1630/ 1703]\n",
      "loss: 3.722645, seq_len:   19 [ 1640/ 1703]\n",
      "loss: 2.470575, seq_len:   33 [ 1650/ 1703]\n",
      "loss: 3.238836, seq_len:   21 [ 1660/ 1703]\n",
      "loss: 3.221165, seq_len:   21 [ 1670/ 1703]\n",
      "loss: 3.195313, seq_len:   22 [ 1680/ 1703]\n",
      "loss: 3.671435, seq_len:   17 [ 1690/ 1703]\n",
      "loss: 3.012058, seq_len:   22 [ 1700/ 1703]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tn = torch.load(\"translation_model.mdl\")\n",
    "except:\n",
    "    tn = Translator().to(device)\n",
    "\n",
    "print(tn)\n",
    "print(\"Total params: \", sum(p.numel() for p in tn.parameters() if p.requires_grad))\n",
    "\n",
    "# training\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(tn.parameters(), lr=1e-5) \n",
    "\n",
    "def train(model, dataloader):\n",
    "    size = len(dataloader)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        loss = 0\n",
    "\n",
    "        for i in range(0, y.shape[1]):\n",
    "\n",
    "            translated_sentence = y[:, 0:i]\n",
    "            result = y[:, i]\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model(X, translated_sentence, i)\n",
    "            loss += loss_fn(pred, result)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(tn.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch)\n",
    "            #max_param =torch.max(torch.nn.utils.parameters_to_vector(tn.parameters())).item()\n",
    "            seq_len = y.shape[1]\n",
    "\n",
    "            loss /= y.shape[1] # normalize with the length of the batch\n",
    "            print(f\"loss: {loss:>7f}, seq_len: {seq_len:>4d} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "train(tn, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tn, \"translation_model.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "['.', '<eos>', 'vous', 'que', 'tom']\n",
      "['.', '<eos>', 'vous', 'que', 'tom']\n",
      "['.', '<eos>', 'vous', 'que', 'tom']\n",
      "['.', '<eos>', 'vous', 'que', 'tom']\n",
      "['.', '<eos>', 'vous', 'que', 'tom']\n",
      "['vous', 'vous', 'vous', 'vous', 'vous']\n"
     ]
    }
   ],
   "source": [
    "def translate(str_en, beginning):\n",
    "\n",
    "    cnt = 5\n",
    "    str_en = en_tokenizer(str_en.lower())\n",
    "    ret = fr_tokenizer(beginning.lower())\n",
    "    \n",
    "    tn.train(False)\n",
    "\n",
    "    # en\n",
    "    en = torch.LongTensor([en_vocab[k] for k in str_en] + [EOS_EN]).to(device)\n",
    "    # batch dimension\n",
    "    en = en[None, :]\n",
    "    print(en.shape)\n",
    "    ret = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = -1\n",
    "\n",
    "        while pred != EOS_FR and cnt > 0:\n",
    "            so_far = torch.LongTensor(ret)[None, :].to(device)\n",
    "            pred = tn(en, so_far)\n",
    "            \n",
    "            #topk = torch.topk(pred.flatten(), 5)\n",
    "            #l = list(topk.indices.cpu().numpy())\n",
    "            #print(fr_vocab.lookup_tokens(l))\n",
    "\n",
    "            pred = torch.argmax(pred)\n",
    "            ret.append(pred)\n",
    "            cnt -= 1\n",
    "\n",
    "    print(fr_vocab.lookup_tokens(ret))\n",
    "\n",
    "\n",
    "translate(\"Let's go!\", \"Allons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.646577835083008 2.722327470779419\n",
      "inf -inf\n",
      "inf -inf\n",
      "inf -inf\n",
      "inf -inf\n",
      "inf -inf\n",
      "inf -inf\n",
      "inf -inf\n",
      "inf -inf\n",
      "inf -inf\n",
      "-0.0776258111000061 0.09099137037992477\n",
      "-4.829888343811035 4.819242000579834\n",
      "-0.16105523705482483 0.1636972576379776\n",
      "-0.16481858491897583 0.16193442046642303\n",
      "-0.1319754421710968 0.15634027123451233\n",
      "-0.12992922961711884 0.158866748213768\n",
      "-0.1434534341096878 0.1386660635471344\n",
      "-0.14836469292640686 0.15485779941082\n",
      "-0.12758702039718628 0.13628582656383514\n",
      "-0.12797050178050995 0.13163629174232483\n",
      "-0.16655927896499634 0.15751993656158447\n",
      "-0.1702856570482254 0.1629342883825302\n",
      "-0.1323714703321457 0.1315317451953888\n",
      "-0.14200709760189056 0.1306927651166916\n",
      "0.9926764965057373 1.007373571395874\n",
      "-0.014029686339199543 0.007941014133393764\n",
      "-0.18592040240764618 0.18469077348709106\n",
      "-0.1234259381890297 0.1225520446896553\n",
      "1.0052403211593628 1.1117478609085083\n",
      "-0.0690707340836525 0.11172597110271454\n",
      "-0.18750400841236115 0.18688464164733887\n",
      "-0.17733626067638397 0.14520761370658875\n"
     ]
    }
   ],
   "source": [
    "def min_max_params():\n",
    "    for p in tn.parameters():\n",
    "    \n",
    "        max__ = p.max().item()\n",
    "        min__ = p.min().item()\n",
    "\n",
    "        print(min__, max__)\n",
    "\n",
    "min_max_params()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
