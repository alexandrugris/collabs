{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexandrugris/.keras/datasets/train.csv\n",
      "/Users/alexandrugris/.keras/datasets/test.csv\n",
      "sex : [b'male' b'female' b'female' b'female' b'male' b'male' b'female' b'female'\n",
      " b'female' b'male']\n",
      "age : [22. 38. 26. 35. 28.  2. 27. 14.  4. 20.]\n",
      "n_siblings_spouses : [1 1 0 1 0 3 0 1 1 0]\n",
      "parch : [0 0 0 0 0 1 2 0 1 0]\n",
      "fare : [ 7.25   71.2833  7.925  53.1     8.4583 21.075  11.1333 30.0708 16.7\n",
      "  8.05  ]\n",
      "class : [b'Third' b'First' b'Third' b'First' b'Third' b'Third' b'Third' b'Second'\n",
      " b'Third' b'Third']\n",
      "deck : [b'unknown' b'C' b'unknown' b'C' b'unknown' b'unknown' b'unknown'\n",
      " b'unknown' b'G' b'unknown']\n",
      "embark_town : [b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Queenstown'\n",
      " b'Southampton' b'Southampton' b'Cherbourg' b'Southampton' b'Southampton']\n",
      "alone : [b'n' b'n' b'y' b'n' b'y' b'n' b'n' b'n' b'n' b'y']\n",
      "survived : [0 1 1 1 0 0 1 1 1 0]\n",
      "OrderedDict([('sex', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'male', b'female', b'female', b'female', b'male', b'male',\n",
      "       b'female', b'female', b'female', b'male'], dtype=object)>), ('age', <tf.Tensor: shape=(10,), dtype=float32, numpy=array([22., 38., 26., 35., 28.,  2., 27., 14.,  4., 20.], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: shape=(10,), dtype=int32, numpy=array([1, 1, 0, 1, 0, 3, 0, 1, 1, 0], dtype=int32)>), ('parch', <tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 1, 2, 0, 1, 0], dtype=int32)>), ('fare', <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 7.25  , 71.2833,  7.925 , 53.1   ,  8.4583, 21.075 , 11.1333,\n",
      "       30.0708, 16.7   ,  8.05  ], dtype=float32)>), ('class', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'Third', b'First', b'Third', b'First', b'Third', b'Third',\n",
      "       b'Third', b'Second', b'Third', b'Third'], dtype=object)>), ('deck', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'unknown', b'C', b'unknown', b'C', b'unknown', b'unknown',\n",
      "       b'unknown', b'unknown', b'G', b'unknown'], dtype=object)>), ('embark_town', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Cherbourg', b'Southampton', b'Southampton',\n",
      "       b'Queenstown', b'Southampton', b'Southampton', b'Cherbourg',\n",
      "       b'Southampton', b'Southampton'], dtype=object)>), ('alone', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'n', b'n', b'y', b'n', b'y', b'n', b'n', b'n', b'n', b'y'],\n",
      "      dtype=object)>)])\n"
     ]
    }
   ],
   "source": [
    "TRAIN_URL = 'http://storage.googleapis.com/tf-datasets/titanic/train.csv'\n",
    "TEST_URL = 'http://storage.googleapis.com/tf-datasets/titanic/test.csv'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "TRAIN_URL = 'http://storage.googleapis.com/tf-datasets/titanic/train.csv'\n",
    "TEST_URL =  'http://storage.googleapis.com/tf-datasets/titanic/eval.csv'\n",
    "\n",
    "train = keras.utils.get_file(\"train.csv\", TRAIN_URL)\n",
    "test = keras.utils.get_file(\"test.csv\", TEST_URL)\n",
    "\n",
    "# print the paths where these files are stored locally\n",
    "print(train)\n",
    "print(test)\n",
    "\n",
    "# does not load the full file in memory, \n",
    "# but rather reads in batches when .take(n) is called\n",
    "# make_csv_dataset has other interesting parameters, such as to recover from errors, \n",
    "# or fill the missing data with a default value\n",
    "train = tf.data.experimental.make_csv_dataset(\n",
    "    train, 10, \n",
    "    label_name=\"survived\",\n",
    "    shuffle=False,\n",
    "    num_epochs=1)\n",
    "\n",
    "def inspect_batch(dataset):\n",
    "    \n",
    "    # read the first batch\n",
    "    for batch, label in dataset.take(1):\n",
    "        \n",
    "        # in batch is everything else, as a dictionary of columns\n",
    "        for k, v in batch.items():\n",
    "            print(f'{k} : {v.numpy()}')\n",
    "            \n",
    "        # it was imported with label (make_csv_dataset invocation)\n",
    "        print(f'survived : {label.numpy()}')\n",
    "        \n",
    "inspect_batch(train)\n",
    "[(train_features, label_batch)] = train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 22:47:43.511816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-05 22:47:43.527093: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.6104155   0.66939646 -0.29046255  0.4294317  -0.13048604 -2.2101805\n",
      " -0.2104743  -1.2503215  -2.050204   -0.77039206], shape=(10,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 22:47:43.723149: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-05 22:47:43.738188: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.49740294  0.67635316 -0.48502994  0.3430459  -0.47525433 -0.24398515\n",
      " -0.42622048 -0.07908852 -0.32418063 -0.48273864], shape=(10,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 22:47:43.938763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-05 22:47:43.955414: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.39519805  0.39519805 -0.47423768  0.39519805 -0.47423768  2.1340694\n",
      " -0.47423768  0.39519805  0.39519805 -0.47423768], shape=(10,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[-0.47905254 -0.47905254 -0.47905254 -0.47905254 -0.47905254  0.78298926\n",
      "  2.045031   -0.47905254  0.78298926 -0.47905254], shape=(10,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-05 22:47:44.183529: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-05 22:47:44.198812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# we will use keras preprocessing layers to process the following features\n",
    "numeric_features = ['age', 'fare', 'n_siblings_spouses', 'parch'] # to be normalized\n",
    "categorical_features = ['class', 'deck', 'embark_town', 'sex', 'alone'] # to be one-hot encoded\n",
    "\n",
    "def get_normalization_layer(ds, col):\n",
    "    layer = keras.layers.Normalization(axis=None)\n",
    "    ds = ds.map(lambda x, y: x[col])\n",
    "    layer.adapt(ds)\n",
    "    return layer\n",
    "\n",
    "def get_categorical_layer(ds, col):\n",
    "    return None\n",
    "\n",
    "preprocessing_inputs = []\n",
    "\n",
    "for nf in numeric_features:\n",
    "    preprocessing_inputs.append(get_normalization_layer(train, nf))\n",
    "    print(preprocessing_inputs[-1](train_features[nf]))\n",
    "\n",
    "for cf in categorical_features:\n",
    "    preprocessing_inputs.append(get_categorical_layer(train, cf))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28726fc3d11b4ff1d3ff9bb8f75f533ae173091b15323d48a7f94c4cdc18037b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
